#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Auto-generated by SimpleNeural-DSL Compiler
Source: examples/iris_classification.sndsl
"""

# ==================== IMPORTS ====================
import tensorflow as tf
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score
import warnings
warnings.filterwarnings("ignore")

# Set random seeds for reproducibility
tf.random.set_seed(42)
np.random.seed(42)


# ==================== DATA LOADING ====================
def load_and_preprocess_data():
    """Load dataset and perform preprocessing."""
    print("[INFO] Loading dataset: Iris.csv")

    try:
        df = pd.read_csv("Iris.csv")
    except FileNotFoundError:
        raise FileNotFoundError(
            f"Dataset 'Iris.csv' not found. "
            "Please ensure the file is in the current directory."
        )

    # Drop ID columns if present
    id_cols = [col for col in df.columns if col.lower() in ['id', 'index', 'unnamed: 0']]
    if id_cols:
        print(f"[INFO] Dropping ID columns: {id_cols}")
        df = df.drop(id_cols, axis=1)

    # Separate features and target (case-insensitive)
    target_col = "Species"
    target_col_actual = None
    for col in df.columns:
        if col.lower() == target_col.lower():
            target_col_actual = col
            break

    if target_col_actual is None:
        raise ValueError(
            f"Target column 'Species' not found (case-insensitive). "
            f"Available columns: {list(df.columns)}"
        )

    y = df.pop(target_col_actual)
    X = df

    # Detect if classification task
    is_classification = y.dtype == 'object' or y.nunique() < 20
    num_classes = 0

    if is_classification:
        print("[INFO] Classification task detected")
        from sklearn.preprocessing import LabelEncoder
        from tensorflow.keras.utils import to_categorical
        le = LabelEncoder()
        y_encoded = le.fit_transform(y)
        num_classes = len(le.classes_)
        print(f"[INFO] Classes ({num_classes}): {list(le.classes_)}")
        if num_classes > 2:
            y = to_categorical(y_encoded, num_classes=num_classes)
            print("[INFO] Applied one-hot encoding for multi-class classification")
        else:
            y = y_encoded  # Binary classification
    else:
        print("[INFO] Regression task detected")
        num_classes = 0

    # Handle missing values
    if X.isnull().any().any():
        print("[WARNING] Dataset contains missing values. Filling with mean...")
        X = X.fillna(X.mean())

    # Feature scaling
    print("[INFO] Applying StandardScaler to features...")
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # Train-test split
    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y,
        test_size=0.2,
        random_state=42
    )

    print(f"[INFO] Training samples: {len(X_train)}")
    print(f"[INFO] Test samples: {len(X_test)}")
    print(f"[INFO] Number of features: {X_train.shape[1]}")

    return X_train, X_test, y_train, y_test, scaler, is_classification, num_classes


# ==================== MODEL DEFINITION ====================
def build_model(input_shape):
    """Build the neural network model: IrisClassifier"""
    print("[INFO] Building model: IrisClassifier")

    model = tf.keras.Sequential([
        tf.keras.layers.InputLayer(input_shape=(input_shape,)),
        tf.keras.layers.Dense(64, activation="relu", name="dense_0"),
        tf.keras.layers.BatchNormalization(name="batchnorm_1"),
        tf.keras.layers.Dense(32, activation="relu", name="dense_2"),
        tf.keras.layers.Dropout(0.2, name="dropout_3"),
        tf.keras.layers.Dense(3, activation="softmax", name="dense_4"),
    ], name="IrisClassifier")

    return model


def compile_model(model, is_classification=False, num_classes=0):
    """Compile model with appropriate loss and metrics"""
    # Configure optimizer
    optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)

    if is_classification:
        if num_classes > 2:
            # Multi-class classification
            model.compile(
                optimizer=optimizer,
                loss="categorical_crossentropy",
                metrics=["accuracy"]
            )
        else:
            # Binary classification
            model.compile(
                optimizer=optimizer,
                loss="binary_crossentropy",
                metrics=["accuracy"]
            )
    else:
        # Regression
        model.compile(
            optimizer=optimizer,
            loss="mse",
            metrics=["mae", "mse"]
        )

    return model


# ==================== TRAINING ====================
def train_model(model, X_train, y_train, X_test, y_test):
    """Train the model with specified parameters."""
    print("\n[INFO] Starting training...")
    print("=" * 50)

    # Ensure models directory exists
    import os
    os.makedirs("models", exist_ok=True)
    model_checkpoint_path = "models/irisclassifier_best.keras"

    # Callbacks for better training control
    callbacks = [
        tf.keras.callbacks.EarlyStopping(
            monitor="val_loss",
            patience=20,  # Increased patience for better convergence
            restore_best_weights=True,
            verbose=1,
            min_delta=0.0001  # Stop if improvement < 0.0001
        ),
        tf.keras.callbacks.ReduceLROnPlateau(
            monitor="val_loss",
            factor=0.5,
            patience=8,  # Reduce LR after 8 epochs without improvement
            min_lr=1e-7,
            verbose=1
        ),
        tf.keras.callbacks.ModelCheckpoint(
            model_checkpoint_path,
            monitor="val_loss",
            save_best_only=True,
            verbose=0
        )
    ]

    # Training
    history = model.fit(
        X_train, y_train,
        epochs=50,
        batch_size=16,
        validation_split=0.15,
        callbacks=callbacks,
        verbose=1
    )

    return history


# ==================== EVALUATION ====================
def evaluate_model(model, X_test, y_test, is_classification=False):
    """Evaluate model performance on test set."""
    print("\n[INFO] Evaluating model on test set...")
    print("=" * 50)

    results = model.evaluate(X_test, y_test, verbose=0)

    if is_classification:
        print(f"Test Loss: {results[0]:.4f}")
        print(f"Test Accuracy: {results[1]:.4f}")

        # Predictions
        predictions = model.predict(X_test, verbose=0)
        y_pred = np.argmax(predictions, axis=1) if len(predictions.shape) > 1 and predictions.shape[1] > 1 else (predictions > 0.5).astype(int)
        y_true = np.argmax(y_test, axis=1) if len(y_test.shape) > 1 and y_test.shape[1] > 1 else y_test
        from sklearn.metrics import classification_report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred))
    else:
        print(f"Test Loss (MSE): {results[0]:.4f}")
        print(f"Test MAE: {results[1]:.4f}")
        print(f"Test RMSE: {np.sqrt(results[0]):.4f}")

        # Predictions
        predictions = model.predict(X_test, verbose=0)

        # R² Score
        r2 = r2_score(y_test, predictions)
        print(f"R² Score: {r2:.4f}")

    return results, predictions


# ==================== MAIN ====================
def main():
    """Main execution function."""
    print("=" * 60)
    print("SimpleNeural-DSL Generated Model")
    print("=" * 60)

    # Load data
    X_train, X_test, y_train, y_test, scaler, is_classification, num_classes = load_and_preprocess_data()

    # Build model
    model = build_model(input_shape=X_train.shape[1])

    # Compile model with appropriate loss
    model = compile_model(model, is_classification, num_classes)

    # Show model summary
    print("\n[INFO] Model Architecture:")
    model.summary()

    # Train model
    history = train_model(model, X_train, y_train, X_test, y_test)

    # Evaluate model
    results, predictions = evaluate_model(model, X_test, y_test, is_classification)

    # Save model
    import os
    os.makedirs("models", exist_ok=True)
    model_path = "models/irisclassifier_final.keras"
    model.save(model_path)
    print(f"\n[INFO] Model saved to: {model_path}")
    print("[INFO] Best model saved to: models/irisclassifier_best.keras")

    print("\n" + "=" * 60)
    print("Training completed successfully!")
    print("=" * 60)

    return model, history, scaler


if __name__ == "__main__":
    model, history, scaler = main()